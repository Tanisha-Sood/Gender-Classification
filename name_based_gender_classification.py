# -*- coding: utf-8 -*-
"""Name Based Gender Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WCrxSTuWYbe6TmsU8QbY5YoMEOoH4q6l

# Name Based Gender Classification Using NLP and Python

### Import Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS

"""### Load the dataset"""

dataset = pd.read_csv("/content/Indian-Name.csv", encoding='latin-1') # or 'cp1252', 'ISO-8859-1', etc.

## dataset1.head()

dataset.head()

"""### Exploratory Data Analysis"""

dataset.columns

## print(dataset1.dtypes)
## print("\n\n")
print(dataset.columns)
print(dataset.dtypes)

dataset['Gender'] = dataset['Target'].replace({0:"M",1:"F"})

dataset = dataset.loc[:,['Name', 'Gender']]

## data = pd.concat([dataset1, dataset2])

dataset.shape

dataset.dtypes

dataset.isnull().sum()

"""It is clear from the above output that there are no missing values in the dataset being used"""

len(dataset['Name'].unique())

dataset['Gender'].unique()

dataset['Gender'].value_counts()

"""Let us create a plot to see how many male and female names are present in the dataset"""

sns.countplot(x='Gender',data = dataset)
plt.title('No. of male and feamle names in the dataset')
plt.xticks([0,1],('Male','Female'))

"""It is evident that there is no class imbalance in the dataset
that is there is no major difference in the no. of names of men and women
"""

dataset['Name'].value_counts()[::-1][:5]

"""This snippet shows the names which occure the least number of times in the dataset

Next, we let us look into how many names start with A, B...Z and their percentage as compared to the entire dataset
"""

alphabets= ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']
total_percent=0
total_count = 0
startletter_count = {}
for i in alphabets:
    print('Number of names starting with {} are '.format(i),len(dataset[dataset['Name'].str.startswith(i)]))
    startletter_count[i] = len(dataset[dataset['Name'].str.startswith(i)])
    print('Percent: ',len(dataset[dataset['Name'].str.contains(i)])/len(dataset['Name'])*100)
    print('\n')
    total_count = total_count + len(dataset[dataset['Name'].str.contains(i)])
    total_percent=total_percent+(len(dataset[dataset['Name'].str.contains(i)])/len(dataset['Name'])*100)
print('Total names = ', total_count)
print("Total percentage = ", total_percent)

print(startletter_count)

plt.figure(figsize = (16,8))
plt.bar(startletter_count.keys(),startletter_count.values())
plt.xlabel('Starting alphabet')
plt.ylabel('No. of names')
plt.title('Number of names starting with each letter')

"""Top 5 alphabets with which most of the namesstart are:"""

# most common starting letter
print('The 5 most name starting letters are : ', *sorted(startletter_count.items(), key=lambda item: item[1])[-5:][::-1])

"""Most rarest in the dataset"""

# the most rarest indian name
print(dataset[dataset['Name'].str.contains('X')])

"""Now, let us see how many names end with the alphabets a,b...z"""

small_alphabets = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','x','y','z']
endletter_count ={}
for i in small_alphabets:
    endletter_count[i]=len(dataset[dataset['Name'].str.endswith(i)])
print(endletter_count)

plt.figure(figsize = (16,8))
plt.bar(endletter_count.keys(),endletter_count.values())
plt.xlabel('Ending alphabet')
plt.ylabel('No. of names')
plt.title('Number of names ending with each letter')

"""Top 5 alphabets with which most of the indian names end are:"""

# most common ending letter
print('The 5 most name ending letters are : ', *sorted(endletter_count.items(), key=lambda item: item[1])[-5:][::-1])

"""Let us now build a word cloud of the names present in the dataset"""

# building a wordcloud
text =  " ".join(i for i in dataset.Name)
word_cloud = WordCloud(
        width=3000,
        height=2000,
        random_state=1,
        background_color="white",
        colormap="BuPu",
        collocations=False,
        stopwords=STOPWORDS,
        ).generate(text)

plt.imshow(word_cloud)
plt.axis("off")
plt.show()

"""### Building a model"""

X =list( dataset['Name'])
Y = list(dataset['Gender'])

"""We encode the 'F' and 'M' labels in the target attribute for easier modeling"""

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
Y = encoder.fit_transform(Y)

"""A count vectorizer is used to convert string-type names into array-like data"""

# count vectorization
from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(analyzer='char')
X=cv.fit_transform(X).toarray()

"""Splitting the dataset"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

"""### 1) Logistic Regression"""

from sklearn.linear_model import LogisticRegression
LR_model = LogisticRegression()
LR_model.fit(x_train,y_train)

LR_y_pred = LR_model.predict(x_test)

# Naive Bayes

"""### 2) Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB
NB_model = MultinomialNB()
NB_model.fit(x_train,y_train)

NB_y_pred = NB_model.predict(x_test)

"""### 3) XGBoost"""

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)

from xgboost import XGBClassifier
XGB_model = XGBClassifier(use_label_encoder= False)
XGB_model.fit(x_train,y_train)

XGB_y_pred = XGB_model.predict(x_test)

"""### Result Comparison"""

from sklearn.metrics import confusion_matrix
def cmatrix(model):
    y_pred = model.predict(x_test)
    cmatrix = confusion_matrix(y_test, y_pred)
    print(cmatrix)
    sns.heatmap(cmatrix,fmt='d',cmap='BuPu',annot=True)
    plt.xlabel('Predicted Values')
    plt.ylabel('Actual Values')
    plt.title('Confusion Matrix')

import sklearn.metrics as metrics
print(metrics.accuracy_score(LR_y_pred,y_test))
print(metrics.classification_report(y_test, LR_y_pred))
print(cmatrix(LR_model))

import sklearn.metrics as metrics
print(metrics.accuracy_score(NB_y_pred,y_test))
print(metrics.classification_report(y_test, NB_y_pred))

cmatrix(NB_model)

print(metrics.accuracy_score(XGB_y_pred,y_test))
print(metrics.classification_report(y_test,XGB_y_pred))

cmatrix(XGB_model)

"""### 4) LSTM"""

#LSTM

from tensorflow.keras import models
from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model
from keras.layers import Embedding
from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, LeakyReLU
from tensorflow.keras.layers import BatchNormalization, Activation, Conv2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dense, Dropout
from tensorflow.keras.layers import LSTM

max_words = 1000
max_len = 26

"""Defining the LSTM layers"""

LSTM_model = Sequential()
LSTM_model.add(Embedding(max_words,40,input_length=26))
LSTM_model.add(Dropout(0.3))
LSTM_model.add(LSTM(100))
LSTM_model.add(Dropout(0.3))
LSTM_model.add(Dense(64,activation='relu'))
LSTM_model.add(Dropout(0.3))
LSTM_model.add(Dense(1,activation='sigmoid'))
LSTM_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
print(LSTM_model.summary())

"""Training the LSTM model"""

LSTM_model.fit(x_train,y_train,epochs=100,batch_size=64)

"""Saving the model"""

LSTM_model.save('NameGenderClassification.hdf5')

import pickle
pickle.dump(LSTM_model, open("model.pickle", 'wb'))

import pickle
pickle.dump(cv, open("cv.pickle", "wb"))

"""Making a sample prediction"""



def predict(name):
    name_samplevector = cv.transform([name]).toarray()
    prediction = LSTM_model.predict([name_samplevector])
    if prediction >=0.7:
        out = 'Male ♂'
    else:
        out = 'Female ♀'
    print(name+' is a '+ out)

predict('Tanisha')